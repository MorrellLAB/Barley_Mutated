#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=10
#SBATCH --mem=80gb
#SBATCH --tmp=70gb
#SBATCH -t 02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=liux1299@umn.edu
#SBATCH -p ram256g,ram1t
#SBATCH -o %A_%a.out
#SBATCH -e %A_%a.err

set -e
set -o pipefail

# Dependencies
module load porechop/0.2.4
module load parallel

# User provided input arguments
FASTQ_LIST=/panfs/roc/groups/9/morrellp/shared/Datasets/Nanopore/Barley_mk1c/mutated_barley_fastq_list.txt
# Number of reads to check for adapters
NUM_READS="10000"
OUT_DIR=/panfs/roc/groups/9/morrellp/shared/Datasets/Alignments/nanopore_mutated_barley/trimmed_fastq

#---------------------
# Check if out dir exists, if not make it
mkdir -p ${OUT_DIR}

FASTQ_ARR=($(cat ${FASTQ_LIST}))

function np_adapter_trimming() {
    local fastq="$1"
    local num_reads="$2"
    local out_dir="$3"
    # Generate basename
    # Works for both .fastq.gz and .fastq files
    if [[ "${fastq}" == *".fastq.gz"* ]]; then
        # We are working with a gzipped fastq file
        out_prefix=$(basename ${fastq} .fastq.gz)
    else
        # We are working with a fastq file
        out_prefix=$(basename ${fastq} .fastq)
    fi
    # Trim adapters
    # Save stdout to log file
    porechop -i ${fastq} \
        --check_reads ${num_reads} \
        -t 8 \
        -o ${out_dir}/${out_prefix}_trimmed.fastq.gz \
        &> ${out_dir}/${out_prefix}.log
}

export -f np_adapter_trimming

np_adapter_trimming ${FASTQ_ARR[${SLURM_ARRAY_TASK_ID}]} ${NUM_READS} ${OUT_DIR}
